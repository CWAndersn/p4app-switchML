# SwitchML Configuration file
# This is where you can configure all SwitchML options.
# SwitchML looks for and parses this configuration file as soon as
# you start the context (unless you pass a Config object to its Start function).
# It looks for it in the following order:
#   1- /etc/switchml.cfg
#   2- ./switchml.cfg
#   3- ./switchml-<hostname>.cfg  (Ex. ./switchml-node12.config)

# General options.
[general]

# A unique identifier for a worker node. Like MPI ranks.
# Create a different configuration file for each worker node with this rank changed.
rank = 0

# The number of worker nodes in the system
num_workers = 1

# The number of worker threads to launch for each node.
# Each thread will typically be bound to a seperate core that is on the same numa
# node as the NIC.
num_worker_threads = 8

# The maximum number of pending packets for this **worker** (Not worker thread).
#
# This number is divided between worker threads.
# This means that each worker thread will first send its initial
# burst up to this number divided by num_worker_threads. Then sends new packets only after packets are received
# doing this until all packets have been sent.
# If you have this set to 256 and num_worker_threads set to 8 then each worker thread will send up to 32 packets.
max_outstanding_packets = 512

# The number of elements in a packet
packet_numel = 256

# Which backend should the SwitchML client use?.
# Choose from ['dummy', 'dpdk', 'rdma'].
# You can read about each backend through its class documentation.
# Make sure that the backend you choose has been compiled.
backend = rdma

# Which scheduler should we use to dispatch jobs to worker threads?.
# Choose from ['fifo'].
# You can read about each scheduler through its class documentation.
scheduler = fifo

# Which prepostprocessor should we use to load and unload the data into and from the network.
# Choose from ['bypass', 'cpu_exponent_quantizer']
prepostprocessor = bypass

# If set to true then all jobs will be instantly completed regardless of the job type.
# This is used for debugging to disable all backend communication.
# The backend is still used to setup and cleanup.
instant_job_completion = false

# The IP address of the machine that's running the controller program.
# Note: This is not the same as the ip address that is passed to the switch_ip
# argument when starting the controller.
controller_ip =  128.30.93.5

# The port that the controller program is using. This is the value that you 
# passed to the port argument when starting the controller.
controller_port = 50099

# Backend options are appended after this point.

# How much time in ms should we wait before we consider that a packet is lost.
# 
# Each worker thread creates a copy of this value at the start of working on a job slice.
# From that point the timeout value can be increased if the number of timeouts exceeds a threshold
# as a backoff mechanism.
timeout = 10

# How many timeouts should occur before we double the timeout time?
timeout_threshold = 100

# By how much should we increment the threshold each time its exceeded.
# (Setting the bar higher to avoid doubling the timouet value too much) 
timeout_threshold_increment = 100

[backend.dummy]

# The bandwidth (in Mbps) that will be used to calculate sleeping durations for communication.
# Set it to 0 to disable sleeping.
bandwidth = 100000.0

# Should the dummy backend actually compute what the tensor values would be if it had done
# Real aggregation? that is should it multiply each tensor element by the number of workers?
# With a real backend this would be done on the switch not slowly on our CPU.
# The dummy backend assumes that the values received are big endian int32 as what would the switch receive.
process_packets = true

[backend.rdma]

# RDMA sends messages then the NIC splits a message into multiple packets.
# Thus the number of elements in a message must be a multiple of a packet's number of elements.
# This reduced the overheads involved in sending packet by packet. However,
# it also makes losses more costly for UC transport since the loss of a single packet will
# make us retransmit the whole message. Hence you should tweak this value until you find the sweet spot.
msg_numel = 4096

# The name of the Infiniband device to use. It will be something like `mlx5_0`.
# You can run the `ibv_devices` command to list your available devices.
device_name = mlx5_0

# Each Infiniband device can have multiple ports.
# This value lets you choose a specific port. 
# Use the `ibv_devinfo` command to list all ports in each device and see their id/index.
# Its the first number in the description of a port "port:   1" means you should use 1 
# for this variable.
device_port_id = 1

# Choose from the following:
# 0: RoCEv1 with MAC-based GID, 1:RoCEv2 with MAC-based GID,
# 2: RoCEv1 with IP-based GID, 3: RoCEv2 with IP-based GID
gid_index = 3

# (Not implemented yet)
# Whether to try to use GPU Direct or not.
# Incase the submitted job's data resides on the GPU, then using GPU Direct allows us to have our registerd buffer
# be also in GPU memory and directly send data from the GPU instead of having to copy it to a registered CPU buffer.
# use_gdr = true
